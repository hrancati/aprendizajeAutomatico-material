{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_04_implementacion_arboles-published.ipynb)\n",
    "\n",
    "## Árboles de decisión\n",
    "\n",
    "### Metiendonos debajo del capot\n",
    "\n",
    "En esta notebook exploraremos el funcionamiento de un árbol de decisión construido aquí mismo.\n",
    "\n",
    "Para eso contaremos con algunas partes de código resueltas y otras que se deberán completar.\n",
    "\n",
    "El objetivo será comprender la esencia de cómo se comportan los árboles a medida que le vamos agregando funcionalidad (o introduciendo _bugs_) para entender mejor su funcionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede ser necesario instalar graphviz\n",
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos bibliotecas necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "import operator # Trae los operadores de Python como funciones y no infix\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from graphviz import Digraph\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de esta notebook usaremos objetos de distintos tipos de datos. Por simplicidad diremos que en todos los casos asumiremos que los parámetros pasados para cada función serán de los siguientes tipos:\n",
    "\n",
    "   - el parámetro `instancias` será un `DataFrame` de `pandas`\n",
    "   - el parámetro `etiquetas` será un `array` de `numpy` con valores `'Si'`, `'No'` (mismo para `etiquetas_rama_izquierda` y `etiquetas_rama_derecha`)\n",
    "   - el parámetro `pregunta` será un objeto de la clase `Decision` que es definida en este mismo archivo\n",
    "\n",
    "\n",
    "La clase Árbol que definiremos a continuación, consta de:\n",
    "\n",
    "   - un constructor\n",
    "   - el método `fit` para entrenarlo (a modo de sklearn)\n",
    "   - el método `predict` para dada una instancia predecir su etiqueta\n",
    "   - el método `score` no se encuentra implementar aún\n",
    "   - métodos para visualizar y explorar el árbol\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase árbol\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        decision=None,  # Esto va a tener tipo Decision, una clase que vamos a definir más adelante\n",
    "        left: Optional[\"Tree\"] = None,\n",
    "        right: Optional[\"Tree\"] = None,\n",
    "        labels: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        self.decision = decision\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "        self.data = Counter(labels) if labels is not None else None\n",
    "\n",
    "    def fit(self, instancias: pd.DataFrame, etiquetas: np.ndarray):\n",
    "        # ALGORITMO RECURSIVO para construcción de un árbol de decisión binario.\n",
    "\n",
    "        # Suponemos que estamos parados en la raiz del árbol y tenemos que decidir cómo construirlo.\n",
    "        gain, decision = encontrar_mejor_atributo_y_corte(instancias, etiquetas)\n",
    "\n",
    "        # Criterio de corte: ¿Hay ganancia?\n",
    "        if gain <= 0:\n",
    "            #  Si no hay ganancia en separar, no separamos.\n",
    "            self.data = Counter(etiquetas)\n",
    "        else:\n",
    "            # Si hay ganancia en partir el conjunto en 2\n",
    "            (\n",
    "                instancias_cumplen,\n",
    "                etiquetas_cumplen,\n",
    "                instancias_no_cumplen,\n",
    "                etiquetas_no_cumplen,\n",
    "            ) = partir_segun(decision, instancias, etiquetas)\n",
    "            # partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)\n",
    "\n",
    "            # Paso recursivo (consultar con el computadorX más cercano)\n",
    "            sub_arbol_izquierdo = Tree()\n",
    "            sub_arbol_izquierdo.fit(instancias_cumplen, etiquetas_cumplen)\n",
    "            sub_arbol_derecho = Tree()\n",
    "            sub_arbol_derecho.fit(instancias_no_cumplen, etiquetas_no_cumplen)\n",
    "            # los pasos anteriores crean todo lo que necesitemos de sub-árbol izquierdo y sub-árbol derecho\n",
    "\n",
    "            self.decision = decision\n",
    "            self.left = sub_arbol_izquierdo\n",
    "            self.right = sub_arbol_derecho\n",
    "            self.data = Counter(etiquetas)\n",
    "\n",
    "    def predict(self, x_t: pd.Series) -> str:\n",
    "        if self.decision is None:\n",
    "            if self.data[\"positive\"] > self.data[\"negative\"]:\n",
    "                return \"positive\"\n",
    "            else:\n",
    "                return \"negative\"\n",
    "        else:\n",
    "            if self.decision.test(x_t):\n",
    "                return self.left.predict(x_t)\n",
    "            else:\n",
    "                return self.right.predict(x_t)\n",
    "\n",
    "    def score(self, X_test: pd.DataFrame, y_test: np.ndarray) -> float:\n",
    "        # COMPLETAR\n",
    "        pass\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self._imprimir_arbol()\n",
    "\n",
    "    def _imprimir_arbol(self, spacing: str = \"\") -> str:\n",
    "        res = []\n",
    "        if self.decision is None:\n",
    "            res.append(spacing + f\"Hoja: {dict(self.data)}\")\n",
    "        else:\n",
    "            res.append(spacing + f\"{str(self.decision)} - {dict(self.data)}\")\n",
    "\n",
    "        if self.left is not None:\n",
    "            res.append(spacing + \"--> True:\")\n",
    "            res.append(self.left._imprimir_arbol(spacing + \"  \"))\n",
    "\n",
    "        if self.right is not None:\n",
    "            res.append(spacing + \"--> False:\")\n",
    "            res.append(self.right._imprimir_arbol(spacing + \"  \"))\n",
    "\n",
    "        return \"\\n\".join(res)\n",
    "\n",
    "    def render(self) -> Digraph:\n",
    "        dot = Digraph()\n",
    "\n",
    "        self.dot_tree_aux(self, dot, prefix=\"\")\n",
    "\n",
    "        return dot\n",
    "\n",
    "    def dot_tree_aux(self, subtree: \"Tree\", dot: Digraph, prefix: str):\n",
    "        label = [\n",
    "            (\n",
    "                f\"{subtree.decision.feature}: {subtree.decision.value}\"\n",
    "                if subtree.decision is not None\n",
    "                else \"\"\n",
    "            ),\n",
    "            f\"n={sum(subtree.data.values())}\",\n",
    "            str(dict(subtree.data)),\n",
    "        ]\n",
    "        label = \"\\n\".join(label)\n",
    "        col = \"#029E3980\" if subtree.data.most_common(1)[0][0] == \"Si\" else \"#EA080080\"\n",
    "        dot.node(prefix + \"n\", label=label, shape=\"box\", fillcolor=col, style=\"filled\")\n",
    "\n",
    "        if subtree.left:\n",
    "            self.dot_tree_aux(subtree.left, dot, prefix + \"l\")\n",
    "            dot.edge(prefix + \"n\", prefix + \"ln\", label=\"True\")\n",
    "\n",
    "        if subtree.right:\n",
    "            self.dot_tree_aux(subtree.right, dot, prefix + \"r\")\n",
    "            dot.edge(prefix + \"n\", prefix + \"rn\", label=\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la decisiones en cada nodo tendremos la siguiente clase. Actualmente funciona comparando por igualdad, pero podría ser extendida en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class Decision:\n",
    "    def __init__(self, feature: str, value: Any, test_function=operator.eq):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.test_function = test_function\n",
    "\n",
    "    def test(self, x: pd.Series) -> bool:\n",
    "        # Devuelve verdadero si la instancia cumple con la pregunta\n",
    "        return self.test_function(self.value, x[self.feature])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"¿Es el valor para {} igual a {}?\".format(self.feature, self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones a completar\n",
    "\n",
    "Primero definir la función `gini`, que dado unas etiquetas dan el grado de impureza (ver definición en la teórica), se espera que devuelva un `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(etiquetas: np.ndarray) -> float:\n",
    "    # COMPLETAR\n",
    "    # clases: \n",
    "    clases, contadores = np.unique(etiquetas, return_counts = True)\n",
    "    probabilidades = contadores / len(etiquetas)\n",
    "    sumaCuadrados = probabilidades*probabilidades\n",
    "    #print(f\"clases:{clases} contadores:{contadores} probabilidades:{probabilidades} sumaCuadrados:{sumaCuadrados}\")\n",
    "    impureza = 1 - np.sum(sumaCuadrados)\n",
    "    return impureza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini de instancias exactamente repartidas: 0.5\n",
      "gini de instancias mas repartidas: 0.4444444444444444\n",
      "gini de instancias iguales: 0.0\n"
     ]
    }
   ],
   "source": [
    "# PRUEBA DE GINI\n",
    "print(f\"gini de instancias exactamente repartidas:\",gini([0,0,1,1]))\n",
    "print(f\"gini de instancias mas repartidas:\",gini([0,0,1]))\n",
    "print(f\"gini de instancias iguales:\",gini([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la función `ganancia_gini` que dadas ciertas instancias y una posible separación entre dos ramas nos de la mejora que obtendremos al separar de esta manera. Devuelve un `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia_gini(etiquetas_rama_izquierda: np.ndarray, etiquetas_rama_derecha: np.ndarray) -> float:\n",
    "    # COMPLETAR\n",
    "    G1 = gini(etiquetas_rama_izquierda)\n",
    "    G2 = gini(etiquetas_rama_derecha)\n",
    "    N1 = etiquetas_rama_izquierda.Size\n",
    "    N2 = etiquetas_rama_derecha.Size\n",
    "    N = N1+N2\n",
    "    \n",
    "    ganancia_gini = 0\n",
    "    return ganancia_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir `partir_segun` que debe separar instancias y etiquetas según si cada instancia cumple o no con condición (ver método `test` de la clase `Decision`).\n",
    "\n",
    "Para este punto se recomienda la utilizacion de máscaras de pandas (ver Notebook 01 - Herramientas).\n",
    "\n",
    "Siguiendo con lo mencionado al inicio del NoteBook, la función debe devolver:\n",
    "\n",
    "   - 2 `DataFrame` de `pandas` con las instancias que cumplen (`instancias_cumplen`) y las que no `instancias_no_cumplen`\n",
    "   - 2 `array` de `numpy` con valores `'Si'`, `'No'`, uno con el valor de la etiqueta para las intancias que cumplen con la pregunta (`etiquetas_cumplen`) y otro con las etiquetas de las que no cumple (`etiquetas_cumplen`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partir_segun(\n",
    "    pregunta: Decision, \n",
    "    instancias: pd.DataFrame, \n",
    "    etiquetas: np.ndarray\n",
    ") -> Tuple[pd.DataFrame, np.ndarray, pd.DataFrame, np.ndarray]:\n",
    "    # Esta función debe separar instancias y etiquetas según si cada instancia cumple o no\n",
    "    # COMPLETAR\n",
    "    (instancias_cumplen,\n",
    "         etiquetas_cumplen,\n",
    "         instancias_no_cumplen,\n",
    "         etiquetas_no_cumplen) = [], [], [], []\n",
    "\n",
    "    return instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se propone una implementación para poder encontrar el mejor atributo y corte posible. Esta función devuelve un `float` y una `Decision` correspondientes al mejor atributo y corte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_mejor_atributo_y_corte(\n",
    "    instancias: pd.DataFrame, etiquetas: np.ndarray\n",
    ") -> Tuple[float, Decision]:\n",
    "    # Implementación Gini Gain.\n",
    "    max_ganancia = 0\n",
    "    mejor_pregunta = None\n",
    "    for columna in instancias.columns:\n",
    "        for valor in set(instancias[columna]):\n",
    "            # Probando corte para atributo y valor\n",
    "            pregunta = Decision(columna, valor)\n",
    "            _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun(\n",
    "                pregunta, instancias, etiquetas\n",
    "            )\n",
    "            if len(etiquetas_rama_izquierda) == 0 or len(etiquetas_rama_derecha) == 0:\n",
    "                continue\n",
    "\n",
    "            ganancia = ganancia_gini(etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "\n",
    "            if ganancia > max_ganancia:\n",
    "                max_ganancia = ganancia\n",
    "                mejor_pregunta = pregunta\n",
    "\n",
    "    return max_ganancia, mejor_pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado el siguiente dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import sklearn.model_selection\n",
    "\n",
    "tictactoe = fetch_openml(name='tic-tac-toe', version=1, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "                    tictactoe['data'], \n",
    "                    tictactoe['target'], \n",
    "                    random_state=4, \n",
    "                    test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar las funciones previas, entrenar y visualizar un Árbol de Decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoja: {'negative': 295, 'positive': 567}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"256pt\" height=\"62pt\"\n",
       " viewBox=\"0.00 0.00 256.00 62.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 58)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-58 252,-58 252,4 -4,4\"/>\n",
       "<!-- n -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>n</title>\n",
       "<polygon fill=\"#ea0800\" fill-opacity=\"0.501961\" stroke=\"black\" points=\"248,-54 0,-54 0,0 248,0 248,-54\"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">n=862</text>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">{&#39;negative&#39;: 295, &#39;positive&#39;: 567}</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7adff808b850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol = Tree()\n",
    "arbol.fit(X_train, y_train)\n",
    "print(arbol)\n",
    "arbol.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar instancias en el árbol podemos elegir alguna del conjunto de testeo y evaluarlas de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para una instancia {'top-left-square': 'x', 'top-middle-square': 'x', 'top-right-square': 'o', 'middle-left-square': 'x', 'middle-middle-square': 'x', 'middle-right-square': 'b', 'bottom-left-square': 'o', 'bottom-middle-square': 'o', 'bottom-right-square': 'o'} obtuve positive\n",
      "Para una instancia {'top-left-square': 'o', 'top-middle-square': 'b', 'top-right-square': 'x', 'middle-left-square': 'o', 'middle-middle-square': 'x', 'middle-right-square': 'x', 'bottom-left-square': 'o', 'bottom-middle-square': 'b', 'bottom-right-square': 'b'} obtuve positive\n",
      "Para una instancia {'top-left-square': 'b', 'top-middle-square': 'o', 'top-right-square': 'b', 'middle-left-square': 'x', 'middle-middle-square': 'o', 'middle-right-square': 'b', 'bottom-left-square': 'x', 'bottom-middle-square': 'o', 'bottom-right-square': 'x'} obtuve positive\n",
      "Para una instancia {'top-left-square': 'x', 'top-middle-square': 'x', 'top-right-square': 'x', 'middle-left-square': 'b', 'middle-middle-square': 'b', 'middle-right-square': 'o', 'bottom-left-square': 'o', 'bottom-middle-square': 'b', 'bottom-right-square': 'b'} obtuve positive\n"
     ]
    }
   ],
   "source": [
    "xs_nuevo = X_test.head(4).to_dict(orient='records')\n",
    "\n",
    "for instancia in xs_nuevo:\n",
    "    res = arbol.predict(instancia)\n",
    "    print(f\"Para una instancia {instancia} obtuve {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Se obtuvieron los valores esperados? Explorar al menos 1 caso por cada rama del árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de los atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, implementaremos dos métodos distintos para medir la importancia de los atributos en nuestro árbol de decisión. Estos métodos nos permitirán entender mejor qué variables tienen mayor influencia en las predicciones del modelo. El primer método que implementaremos es la Importancia Gini, que se basa en la reducción de la impureza Gini en cada nodo del árbol. El segundo método es la Importancia por Permutación, que evalúa cuánto empeora el rendimiento del modelo cuando los valores de una característica se permutan aleatoriamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gini importance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (181093634.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    gini_gain = #COMPLETAR\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def gini_importance(tree: Tree) -> dict:\n",
    "    \"\"\"\n",
    "    Calcula la Disminución Media en la Impureza (Importancia Gini) para un árbol de decisión entrenado.\n",
    "\n",
    "    Argumentos:\n",
    "    - arbol: Una instancia de Tree entrenada\n",
    "\n",
    "    Retorna:\n",
    "    - Un diccionario que asocia los nombres de los atributos con sus puntajes de importancia Gini\n",
    "    \"\"\"\n",
    "    \n",
    "    importance = {}\n",
    "    \n",
    "    def recorrer_arbol(node: Tree, parent_samples: int):\n",
    "        # Si es una hoja termina la recursión\n",
    "        if node.decision is None:  \n",
    "            return\n",
    "        \n",
    "        # Qué atributo se uso en ese nodo\n",
    "        feature = node.decision.feature \n",
    "        \n",
    "        # Si todavia no habiamos usado ese atributo para partir un nodo\n",
    "        if feature not in importance:\n",
    "            importance[feature] = 0\n",
    "        \n",
    "        # Calculamos Gini gain del corte\n",
    "        gini_gain = #COMPLETAR\n",
    "        \n",
    "        \n",
    "        # Actualizamos el valor de ese atributo\n",
    "        importance[feature] = #COMPLETAR\n",
    "        \n",
    "        # Recorrer recursivamente los subárboles\n",
    "        recorrer_arbol(node.left, parent_samples)\n",
    "        recorrer_arbol(node.right, parent_samples)\n",
    "    \n",
    "    # Arrancamos el recorrido desde la raíz\n",
    "    cantidad_total = sum(tree.data.values())\n",
    "    recorrer_arbol(tree, cantidad_total)\n",
    "    \n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_importance(arbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Permutation importance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def permutation_importance(\n",
    "    tree: Tree,\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    score_func: Callable,\n",
    "    n_repeats: int = 10\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calcula la importancia por permutación para los atributos en un árbol entrenado.\n",
    "\n",
    "    Argumentos:\n",
    "    - tree: Instancia de Tree entrenada\n",
    "    - X: DataFrame de atributos\n",
    "    - y: Vector de etiquetas \n",
    "    - score_func: Función para calcular el puntaje (por ejemplo, accuracy_score, r2_score)\n",
    "    - n_repeats: Número de veces para repetir el proceso de permutación\n",
    "\n",
    "    Retorna:\n",
    "    - Diccionario de importancias de los atributos\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calcular el puntaje de referencia\n",
    "    y_pred = np.array([tree.predict(x) for _, x in X.iterrows()])\n",
    "    reference_score = score_func(y, y_pred)\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    importances = {}\n",
    "\n",
    "    for feature in X.columns:\n",
    "        feature_importance = []\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            # Crear una copia de los datos\n",
    "            X_corrupted = #COMPLETAR\n",
    "            \n",
    "            # Permutar aleatoriamente los valores en la columna feature\n",
    "            X_corrupted[feature] = #COMPLETAR\n",
    "            \n",
    "            # Calcular el nuevo score usando los datos corrompidos\n",
    "            corrupted_score = #COMPLETAR\n",
    "            \n",
    "            feature_importance.append(corrupted_score)\n",
    "        \n",
    "        # Calcular la importancia para este atributo según el algoritmo\n",
    "        importances[feature] = #COMPLETAR\n",
    "\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "permutation_importance(arbol, X_train, y_train, accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Se obtienen los mismos valores cuando se calcula sobre el conjunto de testeo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opcional: Atributos continuos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación anterior permite construir árboles partiendo de un dataset cuyos atributos no son continuos. Modificar dicha implementación para que soporte este tipo de atributos.\n",
    "¿Qué funciones hay que modificar? "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
